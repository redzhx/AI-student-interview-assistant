{"ast":null,"code":"var _jsxFileName = \"/Users/zxh/0.Me/Mylearn/AIcoding/mywork/interview-assistant-react_stroop/frontend/src/components/QuestionDisplay.jsx\",\n  _s = $RefreshSig$();\n// frontend/src/components/QuestionDisplay.jsx\nimport React, { useEffect, useRef } from 'react';\nimport axios from 'axios';\nimport { useSettings } from './SettingsContext'; // 确保路径正确\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction QuestionDisplay({\n  question,\n  ttsService,\n  stopAudio\n}) {\n  _s();\n  const audioRef = useRef(null);\n  const {\n    isMuted\n  } = useSettings(); // 获取静音模式状态\n\n  useEffect(() => {\n    if (question && !isMuted) {\n      playAudio(question);\n    }\n\n    // 清理函数，在组件卸载时停止音频播放\n    return () => {\n      if (audioRef.current) {\n        audioRef.current.pause();\n      }\n      speechSynthesis.cancel();\n    };\n  }, [question, isMuted]); // 添加 isMuted 作为依赖\n\n  const playAudio = text => {\n    switch (ttsService) {\n      case 'browser':\n        const utterance = new SpeechSynthesisUtterance(text);\n        speechSynthesis.speak(utterance);\n        break;\n      case 'minimax':\n        axios.post('http://localhost:8000/api/text-to-speech/minimax', {\n          text\n        }, {\n          responseType: 'blob'\n        }).then(response => playAudioBlob(response.data)).catch(error => console.error('Error with Minimax TTS:', error));\n        break;\n      case 'openai':\n        axios.post('http://localhost:8000/api/text-to-speech', {\n          text\n        }, {\n          responseType: 'blob'\n        }).then(response => playAudioBlob(response.data)).catch(error => console.error('Error with OpenAI TTS:', error));\n        break;\n      default:\n        console.error('Unknown TTS service:', ttsService);\n        if (isMuted) return;\n      // 如果静音，不执行任何操作\n    }\n  };\n\n  // if (ttsService === 'browser') {\n  //     const utterance = new SpeechSynthesisUtterance(text);\n  //     speechSynthesis.speak(utterance);\n  //   } else {\n  //     // 外部API音频播放逻辑\n  //     axios.post('...', { text }, { responseType: 'blob' })\n  //       .then(response => {\n  //         const audioUrl = URL.createObjectURL(response.data);\n  //         if (!audioRef.current) {\n  //           audioRef.current = new Audio(audioUrl);\n  //         }\n  //         audioRef.current.play();\n  //       })\n  //       .catch(error => console.error('Error with TTS:', error));\n  //   }\n  // };\n\n  const playAudioBlob = blob => {\n    const audioUrl = URL.createObjectURL(blob);\n    const audio = new Audio(audioUrl);\n    audio.play();\n  };\n\n  // 将此方法暴露给父组件，以便在其他操作时调用\n  useEffect(() => {\n    if (stopAudio) {\n      stopAudio.current = () => {\n        if (audioRef.current) {\n          audioRef.current.pause();\n        }\n        speechSynthesis.cancel();\n      };\n    }\n  }, [stopAudio]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: question || \"没有问题\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 91,\n    columnNumber: 9\n  }, this);\n}\n_s(QuestionDisplay, \"S6QdD2Bs5TWhG8duwPpMYsdKdIU=\", false, function () {\n  return [useSettings];\n});\n_c = QuestionDisplay;\nexport default QuestionDisplay;\nvar _c;\n$RefreshReg$(_c, \"QuestionDisplay\");","map":{"version":3,"names":["React","useEffect","useRef","axios","useSettings","jsxDEV","_jsxDEV","QuestionDisplay","question","ttsService","stopAudio","_s","audioRef","isMuted","playAudio","current","pause","speechSynthesis","cancel","text","utterance","SpeechSynthesisUtterance","speak","post","responseType","then","response","playAudioBlob","data","catch","error","console","blob","audioUrl","URL","createObjectURL","audio","Audio","play","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/zxh/0.Me/Mylearn/AIcoding/mywork/interview-assistant-react_stroop/frontend/src/components/QuestionDisplay.jsx"],"sourcesContent":["// frontend/src/components/QuestionDisplay.jsx\nimport React, { useEffect,useRef } from 'react';\nimport axios from 'axios';\nimport { useSettings } from './SettingsContext'; // 确保路径正确\n\n\nfunction QuestionDisplay({ question, ttsService, stopAudio }) {\n    const audioRef = useRef(null);\n    const { isMuted } = useSettings(); // 获取静音模式状态\n\n\n    useEffect(() => {\n        if (question && !isMuted) {\n            playAudio(question);\n        }\n\n        // 清理函数，在组件卸载时停止音频播放\n        return () => {\n            if (audioRef.current) {\n            audioRef.current.pause();\n            }\n            speechSynthesis.cancel();\n        };\n    }, [question, isMuted]); // 添加 isMuted 作为依赖\n\n    const playAudio = (text) => {\n        switch (ttsService) {\n            \n            case 'browser':\n                const utterance = new SpeechSynthesisUtterance(text);\n                speechSynthesis.speak(utterance);\n                break;\n            case 'minimax':\n                axios.post('http://localhost:8000/api/text-to-speech/minimax', { text }, { responseType: 'blob' })\n                    .then(response => playAudioBlob(response.data))\n                    .catch(error => console.error('Error with Minimax TTS:', error));\n                break;\n            case 'openai':\n                axios.post('http://localhost:8000/api/text-to-speech', { text }, { responseType: 'blob' })\n                    .then(response => playAudioBlob(response.data))\n                    .catch(error => console.error('Error with OpenAI TTS:', error));\n                break;\n            \n            default:\n                console.error('Unknown TTS service:', ttsService);\n            if (isMuted) return; // 如果静音，不执行任何操作\n\n        }\n    };\n\n    // if (ttsService === 'browser') {\n    //     const utterance = new SpeechSynthesisUtterance(text);\n    //     speechSynthesis.speak(utterance);\n    //   } else {\n    //     // 外部API音频播放逻辑\n    //     axios.post('...', { text }, { responseType: 'blob' })\n    //       .then(response => {\n    //         const audioUrl = URL.createObjectURL(response.data);\n    //         if (!audioRef.current) {\n    //           audioRef.current = new Audio(audioUrl);\n    //         }\n    //         audioRef.current.play();\n    //       })\n    //       .catch(error => console.error('Error with TTS:', error));\n    //   }\n    // };\n\n    const playAudioBlob = (blob) => {\n        const audioUrl = URL.createObjectURL(blob);\n        const audio = new Audio(audioUrl);\n        audio.play();\n    };\n\n\n\n    // 将此方法暴露给父组件，以便在其他操作时调用\n    useEffect(() => {\n        if (stopAudio) {\n        stopAudio.current = () => {\n            if (audioRef.current) {\n            audioRef.current.pause();\n            }\n            speechSynthesis.cancel();\n        };\n        }\n    }, [stopAudio]);\n\n\n    return (\n\n        <div>\n            {question || \"没有问题\"}\n        </div>\n    );\n}\n\nexport default QuestionDisplay;\n"],"mappings":";;AAAA;AACA,OAAOA,KAAK,IAAIC,SAAS,EAACC,MAAM,QAAQ,OAAO;AAC/C,OAAOC,KAAK,MAAM,OAAO;AACzB,SAASC,WAAW,QAAQ,mBAAmB,CAAC,CAAC;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAGjD,SAASC,eAAeA,CAAC;EAAEC,QAAQ;EAAEC,UAAU;EAAEC;AAAU,CAAC,EAAE;EAAAC,EAAA;EAC1D,MAAMC,QAAQ,GAAGV,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAM;IAAEW;EAAQ,CAAC,GAAGT,WAAW,CAAC,CAAC,CAAC,CAAC;;EAGnCH,SAAS,CAAC,MAAM;IACZ,IAAIO,QAAQ,IAAI,CAACK,OAAO,EAAE;MACtBC,SAAS,CAACN,QAAQ,CAAC;IACvB;;IAEA;IACA,OAAO,MAAM;MACT,IAAII,QAAQ,CAACG,OAAO,EAAE;QACtBH,QAAQ,CAACG,OAAO,CAACC,KAAK,CAAC,CAAC;MACxB;MACAC,eAAe,CAACC,MAAM,CAAC,CAAC;IAC5B,CAAC;EACL,CAAC,EAAE,CAACV,QAAQ,EAAEK,OAAO,CAAC,CAAC,CAAC,CAAC;;EAEzB,MAAMC,SAAS,GAAIK,IAAI,IAAK;IACxB,QAAQV,UAAU;MAEd,KAAK,SAAS;QACV,MAAMW,SAAS,GAAG,IAAIC,wBAAwB,CAACF,IAAI,CAAC;QACpDF,eAAe,CAACK,KAAK,CAACF,SAAS,CAAC;QAChC;MACJ,KAAK,SAAS;QACVjB,KAAK,CAACoB,IAAI,CAAC,kDAAkD,EAAE;UAAEJ;QAAK,CAAC,EAAE;UAAEK,YAAY,EAAE;QAAO,CAAC,CAAC,CAC7FC,IAAI,CAACC,QAAQ,IAAIC,aAAa,CAACD,QAAQ,CAACE,IAAI,CAAC,CAAC,CAC9CC,KAAK,CAACC,KAAK,IAAIC,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC,CAAC;QACpE;MACJ,KAAK,QAAQ;QACT3B,KAAK,CAACoB,IAAI,CAAC,0CAA0C,EAAE;UAAEJ;QAAK,CAAC,EAAE;UAAEK,YAAY,EAAE;QAAO,CAAC,CAAC,CACrFC,IAAI,CAACC,QAAQ,IAAIC,aAAa,CAACD,QAAQ,CAACE,IAAI,CAAC,CAAC,CAC9CC,KAAK,CAACC,KAAK,IAAIC,OAAO,CAACD,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC,CAAC;QACnE;MAEJ;QACIC,OAAO,CAACD,KAAK,CAAC,sBAAsB,EAAErB,UAAU,CAAC;QACrD,IAAII,OAAO,EAAE;MAAQ;IAEzB;EACJ,CAAC;;EAED;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA,MAAMc,aAAa,GAAIK,IAAI,IAAK;IAC5B,MAAMC,QAAQ,GAAGC,GAAG,CAACC,eAAe,CAACH,IAAI,CAAC;IAC1C,MAAMI,KAAK,GAAG,IAAIC,KAAK,CAACJ,QAAQ,CAAC;IACjCG,KAAK,CAACE,IAAI,CAAC,CAAC;EAChB,CAAC;;EAID;EACArC,SAAS,CAAC,MAAM;IACZ,IAAIS,SAAS,EAAE;MACfA,SAAS,CAACK,OAAO,GAAG,MAAM;QACtB,IAAIH,QAAQ,CAACG,OAAO,EAAE;UACtBH,QAAQ,CAACG,OAAO,CAACC,KAAK,CAAC,CAAC;QACxB;QACAC,eAAe,CAACC,MAAM,CAAC,CAAC;MAC5B,CAAC;IACD;EACJ,CAAC,EAAE,CAACR,SAAS,CAAC,CAAC;EAGf,oBAEIJ,OAAA;IAAAiC,QAAA,EACK/B,QAAQ,IAAI;EAAM;IAAAgC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAClB,CAAC;AAEd;AAAChC,EAAA,CAxFQJ,eAAe;EAAA,QAEAH,WAAW;AAAA;AAAAwC,EAAA,GAF1BrC,eAAe;AA0FxB,eAAeA,eAAe;AAAC,IAAAqC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}