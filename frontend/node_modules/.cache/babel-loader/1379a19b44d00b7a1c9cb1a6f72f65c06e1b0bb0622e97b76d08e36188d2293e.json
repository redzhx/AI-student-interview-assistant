{"ast":null,"code":"var _jsxFileName = \"/Users/zxh/0.Me/Mylearn/AIcoding/mywork/interview-assistant-react_stroop/frontend/src/components/QuestionDisplay.jsx\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef } from 'react';\nimport axios from 'axios';\nimport { useSettings } from '../context/SettingsContext';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction QuestionDisplay({\n  question\n}) {\n  _s();\n  const audioRef = useRef(null);\n  const {\n    isMuted,\n    ttsService\n  } = useSettings();\n  useEffect(() => {\n    if (question && !isMuted) {\n      playAudio(question);\n    }\n    return () => {\n      if (audioRef.current) {\n        audioRef.current.pause();\n      }\n      speechSynthesis.cancel();\n    };\n  }, [question, isMuted]);\n  const playAudio = text => {\n    if (isMuted) return; // 静音模式，不执行任何操作\n\n    switch (ttsService) {\n      case 'browser':\n        const utterance = new SpeechSynthesisUtterance(text);\n        speechSynthesis.speak(utterance);\n        break;\n      case 'minimax':\n        axios.post('http://localhost:8000/api/text-to-speech/minimax', {\n          text\n        }, {\n          responseType: 'blob'\n        }).then(response => playAudioBlob(response.data)).catch(error => console.error('Error with Minimax TTS:', error));\n        break;\n      case 'openai':\n        axios.post('http://localhost:8000/api/text-to-speech', {\n          text\n        }, {\n          responseType: 'blob'\n        }).then(response => playAudioBlob(response.data)).catch(error => console.error('Error with OpenAI TTS:', error));\n        break;\n      default:\n        console.error('Unknown TTS service:', ttsService);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: question || \"没有问题\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 47,\n    columnNumber: 12\n  }, this);\n}\n_s(QuestionDisplay, \"Mz74pf/SKhPw4WhhJCCNP6Fu71s=\", false, function () {\n  return [useSettings];\n});\n_c = QuestionDisplay;\nexport default QuestionDisplay;\nvar _c;\n$RefreshReg$(_c, \"QuestionDisplay\");","map":{"version":3,"names":["React","useEffect","useRef","axios","useSettings","jsxDEV","_jsxDEV","QuestionDisplay","question","_s","audioRef","isMuted","ttsService","playAudio","current","pause","speechSynthesis","cancel","text","utterance","SpeechSynthesisUtterance","speak","post","responseType","then","response","playAudioBlob","data","catch","error","console","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/zxh/0.Me/Mylearn/AIcoding/mywork/interview-assistant-react_stroop/frontend/src/components/QuestionDisplay.jsx"],"sourcesContent":["import React, { useEffect, useRef } from 'react';\nimport axios from 'axios';\nimport { useSettings } from '../context/SettingsContext';\n\nfunction QuestionDisplay({ question }) {\n    const audioRef = useRef(null);\n    const { isMuted, ttsService } = useSettings();\n\n    useEffect(() => {\n        if (question && !isMuted) {\n            playAudio(question);\n        }\n        return () => {\n            if (audioRef.current) {\n                audioRef.current.pause();\n            }\n            speechSynthesis.cancel();\n        };\n    }, [question, isMuted]);\n\n    const playAudio = (text) => {\n        if (isMuted) return; // 静音模式，不执行任何操作\n\n        switch (ttsService) {\n            \n            case 'browser':\n                const utterance = new SpeechSynthesisUtterance(text);\n                speechSynthesis.speak(utterance);\n                break;\n            case 'minimax':\n                axios.post('http://localhost:8000/api/text-to-speech/minimax', { text }, { responseType: 'blob' })\n                    .then(response => playAudioBlob(response.data))\n                    .catch(error => console.error('Error with Minimax TTS:', error));\n                break;\n            case 'openai':\n                axios.post('http://localhost:8000/api/text-to-speech', { text }, { responseType: 'blob' })\n                    .then(response => playAudioBlob(response.data))\n                    .catch(error => console.error('Error with OpenAI TTS:', error));\n                break;\n            \n            default:\n                console.error('Unknown TTS service:', ttsService);\n\n        }\n    };\n\n    return <div>{question || \"没有问题\"}</div>;\n}\n\nexport default QuestionDisplay;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAChD,OAAOC,KAAK,MAAM,OAAO;AACzB,SAASC,WAAW,QAAQ,4BAA4B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEzD,SAASC,eAAeA,CAAC;EAAEC;AAAS,CAAC,EAAE;EAAAC,EAAA;EACnC,MAAMC,QAAQ,GAAGR,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAM;IAAES,OAAO;IAAEC;EAAW,CAAC,GAAGR,WAAW,CAAC,CAAC;EAE7CH,SAAS,CAAC,MAAM;IACZ,IAAIO,QAAQ,IAAI,CAACG,OAAO,EAAE;MACtBE,SAAS,CAACL,QAAQ,CAAC;IACvB;IACA,OAAO,MAAM;MACT,IAAIE,QAAQ,CAACI,OAAO,EAAE;QAClBJ,QAAQ,CAACI,OAAO,CAACC,KAAK,CAAC,CAAC;MAC5B;MACAC,eAAe,CAACC,MAAM,CAAC,CAAC;IAC5B,CAAC;EACL,CAAC,EAAE,CAACT,QAAQ,EAAEG,OAAO,CAAC,CAAC;EAEvB,MAAME,SAAS,GAAIK,IAAI,IAAK;IACxB,IAAIP,OAAO,EAAE,OAAO,CAAC;;IAErB,QAAQC,UAAU;MAEd,KAAK,SAAS;QACV,MAAMO,SAAS,GAAG,IAAIC,wBAAwB,CAACF,IAAI,CAAC;QACpDF,eAAe,CAACK,KAAK,CAACF,SAAS,CAAC;QAChC;MACJ,KAAK,SAAS;QACVhB,KAAK,CAACmB,IAAI,CAAC,kDAAkD,EAAE;UAAEJ;QAAK,CAAC,EAAE;UAAEK,YAAY,EAAE;QAAO,CAAC,CAAC,CAC7FC,IAAI,CAACC,QAAQ,IAAIC,aAAa,CAACD,QAAQ,CAACE,IAAI,CAAC,CAAC,CAC9CC,KAAK,CAACC,KAAK,IAAIC,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC,CAAC;QACpE;MACJ,KAAK,QAAQ;QACT1B,KAAK,CAACmB,IAAI,CAAC,0CAA0C,EAAE;UAAEJ;QAAK,CAAC,EAAE;UAAEK,YAAY,EAAE;QAAO,CAAC,CAAC,CACrFC,IAAI,CAACC,QAAQ,IAAIC,aAAa,CAACD,QAAQ,CAACE,IAAI,CAAC,CAAC,CAC9CC,KAAK,CAACC,KAAK,IAAIC,OAAO,CAACD,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC,CAAC;QACnE;MAEJ;QACIC,OAAO,CAACD,KAAK,CAAC,sBAAsB,EAAEjB,UAAU,CAAC;IAEzD;EACJ,CAAC;EAED,oBAAON,OAAA;IAAAyB,QAAA,EAAMvB,QAAQ,IAAI;EAAM;IAAAwB,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAAM,CAAC;AAC1C;AAAC1B,EAAA,CA3CQF,eAAe;EAAA,QAEYH,WAAW;AAAA;AAAAgC,EAAA,GAFtC7B,eAAe;AA6CxB,eAAeA,eAAe;AAAC,IAAA6B,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}